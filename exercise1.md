Let’s assume we have a large Python ML-project set up. 
For formatting there exists options like autopep8, Pylint, Flake8 or Ruff, if you want a more modern solution. This is to keep a consistent format of the code between all developers improving potential code troubleshooting. With an interpreted language, you can use Mypy for additional type safety, which also improves code consistency when collaborating.
When testing, pytest is a commonly used framework if Python’s own unittest is not sufficient. You can also use pytest-cov for checking the testing coverage of your application. Hence if the amount of tested code gets under a certain percentage, you can set the pipeline to fail. 
During a build, it’s not about compiling code but rather preparing the application environment and dependencies. For this, Poetry is a suitable tool you can use for ensuring that same library versions are used by each developer.
Depending on the applications functionality itself, we could also use alternatives to the cloud-based GitHub Actions, like Bitbucket Pipelines and GitLab CI. GitLab also has an on-prem option and Bitbucket Pipelines offer a "runner" for running builds on your own infrastructure. The choice between self-hosted and cloud-based pipeline solutions usually depends on things like the skillset of the developers, security needs, budget and project size. 
For the sake of this exercise, let’s assume two of the developers can manage the self-hosted setup. There might be a larger set of data science or ML libraries in the environment, which would be tedious to download every time a test is run on a cloud based solution. We can also allocate more CPU resources for running pipelines. In addition to this, self-hosted solutions also enable us to communicate with other internal services directly.